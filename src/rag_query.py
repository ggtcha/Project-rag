import os
import re
import ollama
from typing import List, Generator, Dict, Optional
from dotenv import load_dotenv

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser 
from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_community.vectorstores import PGVector
from langchain_community.chat_message_histories import SQLChatMessageHistory

# ============================================================================
# 1. Setup & Configuration 
# ============================================================================
load_dotenv()

DB_CONFIG = {
    "connection": f"postgresql+psycopg2://{os.getenv('PG_USER')}:{os.getenv('PG_PASSWORD')}@{os.getenv('PG_HOST')}:{os.getenv('PG_PORT')}/{os.getenv('PG_DATABASE')}",
    "collection": os.getenv("COLLECTION_NAME")
}

# ============================================================================
# 2. Resources (Embeddings & Vector Store)
# ============================================================================
embeddings = OllamaEmbeddings(
    model="mxbai-embed-large", 
    base_url="http://localhost:11434"
)

vector_store = PGVector(
    collection_name=DB_CONFIG["collection"],
    connection_string=DB_CONFIG["connection"],
    embedding_function=embeddings,
    use_jsonb=True
)

retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={
        "k": 5,
        "fetch_k": 15,
        "lambda_mult": 0.7    
    }
)

# âš¡ à¹€à¸à¸´à¹ˆà¸¡ num_predict à¹à¸¥à¸°à¸›à¸£à¸±à¸š temperature
chat_llm = ChatOllama(
    model="llama3.2:1b", 
    temperature=0.5,  # à¹€à¸à¸´à¹ˆà¸¡à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›à¹„à¸”à¹‰à¸«à¸¥à¸²à¸à¸«à¸¥à¸²à¸¢
    num_predict=512
)

# ============================================================================
# 3. Utility & Logic
# ============================================================================
def clean_content(text: str) -> str:
    """à¸¥à¸šà¸‚à¸¢à¸°à¸—à¸²à¸‡à¹€à¸—à¸„à¸™à¸´à¸„à¸­à¸­à¸à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡"""
    text = re.sub(r'dtype:\s*\w+|Name:|Unnamed:|\\n|\t', '', text)
    text = re.sub(r'\bNaN\b|\bnan\b|\bNone\b', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def format_docs(docs: List) -> str:
    if not docs: 
        return "à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸£à¸°à¸šà¸š"
    formatted = "\n\n".join([clean_content(doc.page_content) for doc in docs])
    return formatted

def analyze_intent(text: str) -> str:
    """à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸ˆà¸•à¸™à¸² - à¸›à¸£à¸±à¸šà¹ƒà¸«à¹‰à¹à¸¡à¹ˆà¸™à¸¢à¸³à¹à¸¥à¸°à¸£à¸­à¸‡à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›"""
    text_lower = text.lower().strip()
    
    # à¸—à¸±à¸à¸—à¸²à¸¢
    greetings = ["à¸ªà¸§à¸±à¸ªà¸”à¸µ", "hi", "hello", "à¸”à¸µ", "à¸«à¸§à¸±à¸”à¸”à¸µ", "à¸§à¹ˆà¸²à¹„à¸‡", "à¸§à¹ˆà¸²à¸¢à¸±à¸‡à¹„à¸‡", "hey"]
    if len(text.split()) <= 5 and any(g in text_lower for g in greetings):
        return "GREETING"
    
    # à¸„à¸³à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸•à¸±à¸§à¸šà¸­à¸—
    about_bot = [
        "à¸„à¸¸à¸“à¸„à¸·à¸­à¹ƒà¸„à¸£", "à¸„à¸¸à¸“à¸„à¸·à¸­à¸­à¸°à¹„à¸£", "à¸—à¸³à¸­à¸°à¹„à¸£à¹„à¸”à¹‰à¸šà¹‰à¸²à¸‡", "à¸Šà¹ˆà¸§à¸¢à¸­à¸°à¹„à¸£à¹„à¸”à¹‰", 
        "à¸ªà¸²à¸¡à¸²à¸£à¸–à¸—à¸³à¸­à¸°à¹„à¸£", "à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰à¸‡à¸²à¸™", "à¹ƒà¸Šà¹‰à¸¢à¸±à¸‡à¹„à¸‡", "à¸„à¸¸à¸“à¸Šà¸·à¹ˆà¸­à¸­à¸°à¹„à¸£",
        "who are you", "what can you do", "how to use"
    ]
    if any(q in text_lower for q in about_bot):
        return "ABOUT_BOT"
    
    # à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸„à¸¥à¸±à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸² - à¸•à¹‰à¸­à¸‡à¸¡à¸µ keyword à¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™
    warehouse_kw = {
        "serial", "sn", "s/n", "model", "à¸£à¸¸à¹ˆà¸™", "à¸—à¸µà¹ˆà¹„à¸«à¸™", "location", 
        "à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡", "asset", "à¸„à¸¥à¸±à¸‡", "stock", "à¸ªà¸–à¸²à¸™à¸°", "status", 
        "à¸•à¸¶à¸", "à¸­à¸²à¸„à¸²à¸£", "à¸«à¹‰à¸­à¸‡", "spare", "à¸­à¸°à¹„à¸«à¸¥à¹ˆ", "à¸«à¸²", "à¸„à¹‰à¸™à¸«à¸²",
        "obsolete", "à¹€à¸¥à¸´à¸à¹ƒà¸Šà¹‰", "à¸ªà¸³à¸£à¸­à¸‡", "inventory", "warehouse",
        "part", "à¸£à¸«à¸±à¸ª", "code"
    }
    
    # à¸¡à¸µà¸£à¸«à¸±à¸ªà¸ªà¸´à¸™à¸„à¹‰à¸²à¹ƒà¸™à¸„à¸³à¸–à¸²à¸¡ (5 à¸•à¸±à¸§à¸‚à¸¶à¹‰à¸™à¹„à¸›)
    has_code = bool(re.search(r'[A-Z0-9]{5,}', text, re.IGNORECASE))
    
    # à¸¡à¸µ keyword à¸„à¸¥à¸±à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²
    has_warehouse_keyword = any(k in text_lower for k in warehouse_kw)
    
    if has_code or has_warehouse_keyword:
        return "WAREHOUSE_QUERY"
    
    # Default à¹€à¸›à¹‡à¸™à¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸› (à¹ƒà¸«à¹‰ LLM à¸•à¸­à¸šà¹€à¸­à¸‡à¹„à¸”à¹‰)
    return "GENERAL_KNOWLEDGE"

def expand_query(question: str) -> List[str]:
    """à¸‚à¸¢à¸²à¸¢à¸„à¸³à¸„à¹‰à¸™à¸«à¸²"""
    queries = [question]
    codes = re.findall(r'[A-Z0-9]{5,}', question.upper())
    for code in codes[:3]:
        if code not in queries:
            queries.append(code)
    return queries

def analyze_image_with_vision(image_bytes: bytes) -> str:
    """à¸­à¹ˆà¸²à¸™ Serial/Model à¸ˆà¸²à¸à¸£à¸¹à¸›à¸ à¸²à¸"""
    try:
        print("ğŸ–¼ï¸ à¸à¸³à¸¥à¸±à¸‡à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸£à¸¹à¸›à¸ à¸²à¸...")
        
        models_to_try = ['llama3.2-vision:latest', 'llava:latest', 'llama3.2:1b']
        
        for model_name in models_to_try:
            try:
                response = ollama.chat(
                    model=model_name,
                    messages=[{
                        'role': 'user',
                        'content': '''Extract ONLY codes/serial numbers from this image.
Rules:
- List codes separated by commas
- No explanations
- If no codes: reply "unknown"

Your answer:''',
                        'images': [image_bytes]
                    }],
                    options={
                        'num_predict': 50,
                        'temperature': 0.1
                    }
                )
                
                result = response['message']['content'].strip()
                result = result.split('\n')[0].strip()
                result = re.sub(r'["\']', '', result)
                
                print(f"âœ… Vision Result ({model_name}): {result}")
                
                if result and result.lower() not in ['unknown', 'none', 'n/a', '']:
                    return result
                    
            except Exception as model_error:
                print(f"âš ï¸ {model_name} failed: {model_error}")
                continue
        
        return "unknown"
        
    except Exception as e:
        print(f"âŒ Vision Error: {e}")
        return "unknown"

# ============================================================================
# 4. Context & Chain Setup - à¸›à¸£à¸±à¸šà¹ƒà¸«à¹‰à¸£à¸­à¸‡à¸£à¸±à¸šà¸—à¸¸à¸à¸›à¸£à¸°à¹€à¸ à¸—à¸„à¸³à¸–à¸²à¸¡
# ============================================================================
def context_handler(inputs: Dict) -> str:
    """à¸ˆà¸±à¸”à¸à¸²à¸£ Context - à¸£à¸­à¸‡à¸£à¸±à¸šà¸—à¸±à¹‰à¸‡à¸„à¸³à¸–à¸²à¸¡à¸„à¸¥à¸±à¸‡à¹à¸¥à¸°à¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›"""
    question = inputs.get("question", "")
    image_code = inputs.get("image_code", "unknown")
    
    intent = analyze_intent(question)
    
    print(f"ğŸ¯ Intent detected: {intent}")
    
    # à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸—à¸±à¸à¸—à¸²à¸¢ â†’ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸„à¹‰à¸™ Vector DB
    if intent == "GREETING":
        return "SYSTEM_MODE: GREETING"
    
    # à¸–à¹‰à¸²à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸šà¸­à¸— â†’ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸„à¹‰à¸™ Vector DB
    if intent == "ABOUT_BOT":
        return "SYSTEM_MODE: ABOUT_BOT"
    
    # à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸› â†’ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸„à¹‰à¸™ Vector DB
    if intent == "GENERAL_KNOWLEDGE":
        return "SYSTEM_MODE: GENERAL_KNOWLEDGE"
    
    # à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸„à¸³à¸–à¸²à¸¡à¸„à¸¥à¸±à¸‡ â†’ à¸„à¹‰à¸™ Vector DB
    print("ğŸ” Searching warehouse database...")
    search_query = f"{question} {image_code}" if image_code != "unknown" else question
    
    try:
        queries = expand_query(search_query)
        all_docs = []
        seen_hashes = set()
        
        for query in queries[:3]:
            docs = retriever.invoke(query)
            print(f"   ğŸ“„ Query '{query}' â†’ {len(docs)} docs")
            
            for doc in docs:
                doc_hash = hash(doc.page_content)
                if doc_hash not in seen_hashes:
                    seen_hashes.add(doc_hash)
                    all_docs.append(doc)
                    
                    if len(all_docs) >= 5:
                        break
            
            if len(all_docs) >= 5:
                break
        
        if not all_docs:
            return f"SYSTEM_MODE: NOT_FOUND | Query: {question}"
        
        print(f"âœ… Total docs: {len(all_docs)}")
        formatted_context = format_docs(all_docs[:5])
        
        if len(formatted_context) > 2000:
            formatted_context = formatted_context[:2000] + "\n...(truncated)"
        
        return f"WAREHOUSE_DATA:\n{formatted_context}"
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return f"SYSTEM_MODE: ERROR | {str(e)}"

# ============================================================================
# 5. Prompt & Chain - à¸›à¸£à¸±à¸šà¹ƒà¸«à¹‰à¸£à¸­à¸‡à¸£à¸±à¸šà¸—à¸±à¹‰à¸‡à¸„à¸³à¸–à¸²à¸¡à¸„à¸¥à¸±à¸‡à¹à¸¥à¸°à¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›
# ============================================================================
rag_prompt = ChatPromptTemplate.from_messages([
    ("system", """à¸„à¸¸à¸“à¸„à¸·à¸­ **AI Warehouse Assistant** ğŸ¤– à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸„à¸¥à¸±à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¸­à¸±à¸ˆà¸‰à¸£à¸´à¸¢à¸°à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£à¹à¸¥à¸°à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¹„à¸”à¹‰à¸—à¸¸à¸à¹€à¸£à¸·à¹ˆà¸­à¸‡

ğŸ¯ **à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸‚à¸­à¸‡à¸„à¸¸à¸“:**
1. ğŸ“¦ **à¸„à¹‰à¸™à¸«à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸¥à¸±à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²**: Serial Number, Model, à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡, à¸ªà¸–à¸²à¸™à¸°
2. ğŸ’¬ **à¸ªà¸™à¸—à¸™à¸²à¸—à¸±à¹ˆà¸§à¹„à¸›**: à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸—à¸±à¹ˆà¸§à¹„à¸› à¸„à¸¸à¸¢à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸­à¸·à¹ˆà¸™à¹„à¸”à¹‰
3. ğŸ–¼ï¸ **à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸£à¸¹à¸›à¸ à¸²à¸**: à¸­à¹ˆà¸²à¸™à¸£à¸«à¸±à¸ªà¸ˆà¸²à¸à¸£à¸¹à¸›à¹à¸¥à¸°à¸„à¹‰à¸™à¸«à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
4. â“ **à¹ƒà¸«à¹‰à¸„à¸³à¹à¸™à¸°à¸™à¸³**: à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¹à¸¥à¸°à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸¸à¸à¸›à¸£à¸°à¹€à¸ à¸—

---

ğŸ“‹ **à¸à¸à¸à¸²à¸£à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡ (à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸!):**

**à¸à¸£à¸“à¸µà¸—à¸µà¹ˆ 1: à¸–à¹‰à¸² Context = "SYSTEM_MODE: GREETING"**
â†’ à¸—à¸±à¸à¸—à¸²à¸¢à¸à¸¥à¸±à¸šà¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£ à¹à¸™à¸°à¸™à¸³à¸•à¸±à¸§à¹€à¸­à¸‡à¸ªà¸±à¹‰à¸™à¹† à¹à¸¥à¸°à¸šà¸­à¸à¸§à¹ˆà¸²à¸à¸£à¹‰à¸­à¸¡à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­

**à¸à¸£à¸“à¸µà¸—à¸µà¹ˆ 2: à¸–à¹‰à¸² Context = "SYSTEM_MODE: ABOUT_BOT"**
â†’ à¹à¸™à¸°à¸™à¸³à¸•à¸±à¸§à¹€à¸­à¸‡à¸§à¹ˆà¸²à¸„à¸¸à¸“à¸„à¸·à¸­ AI Warehouse Assistant à¹à¸¥à¸°à¸šà¸­à¸à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸—à¸±à¹‰à¸‡ 4 à¸‚à¹‰à¸­à¸‚à¹‰à¸²à¸‡à¸šà¸™

**à¸à¸£à¸“à¸µà¸—à¸µà¹ˆ 3: à¸–à¹‰à¸² Context = "SYSTEM_MODE: GENERAL_KNOWLEDGE"**
â†’ à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›à¹„à¸”à¹‰à¸•à¸²à¸¡à¸›à¸à¸•à¸´ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸‚à¸­à¸‡à¸„à¸¸à¸“à¹€à¸­à¸‡ (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ Context)
â†’ à¸•à¸­à¸šà¹à¸šà¸šà¸à¸£à¸°à¸Šà¸±à¸š à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£ à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸—à¸µà¹ˆà¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸‡à¹ˆà¸²à¸¢

**à¸à¸£à¸“à¸µà¸—à¸µà¹ˆ 4: à¸–à¹‰à¸² Context à¸‚à¸¶à¹‰à¸™à¸•à¹‰à¸™à¸”à¹‰à¸§à¸¢ "WAREHOUSE_DATA:"**
â†’ à¸•à¸­à¸šà¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ Context à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
â†’ à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥: Serial Number, Model, Location, Status, à¸œà¸¹à¹‰à¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸š
â†’ à¸ˆà¸±à¸”à¸£à¸¹à¸›à¹à¸šà¸šà¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¹ƒà¸Šà¹‰à¸­à¸´à¹‚à¸¡à¸ˆà¸´à¸›à¸£à¸°à¸à¸­à¸š
â†’ **à¸«à¹‰à¸²à¸¡** à¹à¸ªà¸”à¸‡ NaN, None, nan, null

**à¸à¸£à¸“à¸µà¸—à¸µà¹ˆ 5: à¸–à¹‰à¸² Context = "SYSTEM_MODE: NOT_FOUND"**
â†’ à¸šà¸­à¸à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸§à¹ˆà¸² "à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸£à¸°à¸šà¸šà¸„à¸¥à¸±à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²"
â†’ à¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸¥à¸­à¸‡à¸„à¹‰à¸™à¸”à¹‰à¸§à¸¢à¸„à¸³à¸­à¸·à¹ˆà¸™ à¸«à¸£à¸·à¸­à¸–à¸²à¸¡à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¸§à¸²à¸¡à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¸­à¸¢à¹ˆà¸²à¸‡à¸­à¸·à¹ˆà¸™à¹„à¸«à¸¡

**à¸à¸£à¸“à¸µà¸—à¸µà¹ˆ 6: à¸–à¹‰à¸² Context = "SYSTEM_MODE: ERROR"**
â†’ à¸šà¸­à¸à¸§à¹ˆà¸²à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸” à¹à¸¥à¸°à¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆ

---

ğŸ’¬ **à¸ªà¹„à¸•à¸¥à¹Œà¸à¸²à¸£à¸•à¸­à¸š:**
- à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£ à¸ªà¸¸à¸ à¸²à¸ à¸à¸£à¸°à¸Šà¸±à¸š à¸Šà¸±à¸”à¹€à¸ˆà¸™
- à¹ƒà¸Šà¹‰à¸­à¸´à¹‚à¸¡à¸ˆà¸´à¹€à¸šà¸²à¹† à¹ƒà¸«à¹‰à¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆ (à¹à¸•à¹ˆà¸­à¸¢à¹ˆà¸²à¸¡à¸²à¸à¹€à¸à¸´à¸™à¹„à¸›)
- à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸à¸±à¸™à¹€à¸­à¸‡ à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸‡à¹ˆà¸²à¸¢
- à¸–à¹‰à¸²à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸› â†’ à¸•à¸­à¸šà¹à¸šà¸šà¸ªà¸±à¹‰à¸™à¹† à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 3-4 à¸›à¸£à¸°à¹‚à¸¢à¸„

---

**Context à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™:**
{context}

---

**à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸à¸ªà¸³à¸„à¸±à¸:** 
- à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸„à¸¥à¸±à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸² à¸„à¸¸à¸“à¸ªà¸²à¸¡à¸²à¸£à¸–à¸•à¸­à¸šà¹„à¸”à¹‰à¹€à¸¥à¸¢à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸¶à¹ˆà¸‡ Context
- à¸–à¹‰à¸²à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸–à¸²à¸¡à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¹ƒà¸ˆ à¸šà¸­à¸à¸•à¸£à¸‡à¹† à¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¹ƒà¸ˆ à¹à¸•à¹ˆà¸à¸¢à¸²à¸¢à¸²à¸¡à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¹ƒà¸«à¹‰à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
- à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸„à¸·à¸­: **à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹ƒà¸«à¹‰à¹„à¸”à¹‰à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸” à¸—à¸±à¹‰à¸‡à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸„à¸¥à¸±à¸‡à¹à¸¥à¸°à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸—à¸±à¹ˆà¸§à¹„à¸›**"""),
    MessagesPlaceholder(variable_name="history"), 
    ("human", "{question}"),
])

rag_chain = (
    RunnablePassthrough.assign(context=context_handler)
    | rag_prompt
    | chat_llm
    | StrOutputParser()
)

# ============================================================================
# 6. Session History
# ============================================================================
def get_session_history(session_id: str):
    """à¸ªà¸£à¹‰à¸²à¸‡ Chat History"""
    if not os.path.exists('data'):
        os.makedirs('data')
    
    history = SQLChatMessageHistory(
        session_id=session_id, 
        connection_string="sqlite:///data/chat_history.db"
    )
    
    # à¹€à¸à¹‡à¸šà¹à¸„à¹ˆ 10 à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸¥à¹ˆà¸²à¸ªà¸¸à¸”
    messages = history.messages
    if len(messages) > 10:
        for msg in messages[:-10]:
            history.messages.remove(msg)
    
    return history

chain_with_history = RunnableWithMessageHistory(
    rag_chain,
    get_session_history, 
    input_messages_key="question", 
    history_messages_key="history", 
)

# ============================================================================
# 7. Main Execution
# ============================================================================
def chat_with_warehouse_system(
    user_id: str, 
    prompt: str, 
    image_bytes: Optional[bytes] = None
) -> Generator[str, None, None]:
    """à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸«à¸¥à¸±à¸ - à¸£à¸­à¸‡à¸£à¸±à¸šà¸—à¸¸à¸à¸›à¸£à¸°à¹€à¸ à¸—à¸„à¸³à¸–à¸²à¸¡"""
    
    print(f"\n{'='*60}")
    print(f"ğŸ”¹ User: {user_id} | Prompt: {prompt[:50]}...")
    
    if not prompt or not prompt.strip():
        prompt = "à¸Šà¹ˆà¸§à¸¢à¸«à¸²à¸£à¸«à¸±à¸ªà¸ªà¸´à¸™à¸„à¹‰à¸²à¸ˆà¸²à¸à¸£à¸¹à¸›à¸ à¸²à¸" if image_bytes else "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š"
    
    image_code = "unknown"
    final_prompt = prompt.strip()

    if image_bytes:
        print("ğŸ“¸ Analyzing image...")
        image_code = analyze_image_with_vision(image_bytes)
        print(f"ğŸ“‹ Code found: {image_code}")
        
        if image_code != "unknown":
            if len(prompt.split()) <= 5:
                final_prompt = f"à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸£à¸«à¸±à¸ª {image_code}"
            else:
                final_prompt = f"{prompt} (à¸£à¸«à¸±à¸ª: {image_code})"
        else:
            final_prompt = f"{prompt} (à¹„à¸¡à¹ˆà¸à¸šà¸£à¸«à¸±à¸ªà¸Šà¸±à¸”à¹€à¸ˆà¸™)"
    
    print(f"{'='*60}\n")
    
    try:
        has_output = False
        buffer = ""
        chunk_count = 0
        
        for chunk in chain_with_history.stream(
            {"question": final_prompt, "image_code": image_code}, 
            config={"configurable": {"session_id": user_id}}
        ):
            if chunk:
                has_output = True
                buffer += chunk
                chunk_count += 1
                
                if chunk_count % 3 == 0 or len(buffer) > 50:
                    yield buffer
                    buffer = ""
        
        if buffer:
            yield buffer
        
        if not has_output:
            yield "âš ï¸ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸”à¹‰ à¸à¸£à¸¸à¸“à¸²à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆ"
            
    except Exception as e:
        error_msg = f"âš ï¸ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”: {str(e)}"
        print(f"âŒ Exception: {error_msg}")
        yield error_msg

def chat_with_lm(user_id: str, prompt: str) -> Generator[str, None, None]:
    """Wrapper à¸ªà¸³à¸«à¸£à¸±à¸š backward compatibility"""
    return chat_with_warehouse_system(user_id, prompt, None)